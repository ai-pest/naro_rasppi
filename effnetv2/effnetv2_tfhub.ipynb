{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetV2 å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»TFLite åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
      ],
      "metadata": {
        "id": "-kmvEuIX30AZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# å­¦ç¿’ãƒ»è©•ä¾¡ã®æº–å‚™"
      ],
      "metadata": {
        "id": "qVfDt8hnfGmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## èªè¨¼\n",
        "\n",
        "Google Cloud Storage ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆã¯ã€æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦èªè¨¼å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚\n",
        "\n",
        "> ï¸ğŸ“˜ãƒãƒ¼ãƒˆ\n",
        ">\n",
        "> * ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆã¯ã€ã“ã®æ‰‹é †ã¯ä¸è¦ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "AWFjABnySVbW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt_tiRnpIb1i"
      },
      "source": [
        "## EfficientNet-V2 TF-Hub ç‰ˆ\n",
        "## ver. 20220118\n",
        "\n",
        "!mkdir -p /content\n",
        "!gcloud auth application-default login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive ã®ãƒã‚¦ãƒ³ãƒˆ\n",
        "\n",
        "Google Drive ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆã¯ã€æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ Google Drive ã‚’ä»®æƒ³ãƒã‚·ãƒ³ã«ãƒã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚\n",
        "\n",
        "Google Drive ã¯ `/content/drive/MyDrive` ã«ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "> ï¸ğŸ“˜ãƒãƒ¼ãƒˆ\n",
        ">\n",
        "> * ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ Google Cloud Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆã¯ã€ã“ã®æ‰‹é †ã¯ä¸è¦ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "JdIYOcHoexke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-gkhy2DGeyAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn1Y5ZtCCce2"
      },
      "source": [
        "## å­¦ç¿’ãƒ»è©•ä¾¡ã®è¨­å®š"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-01T00:30:50.930935Z",
          "iopub.execute_input": "2021-11-01T00:30:50.931472Z",
          "iopub.status.idle": "2021-11-01T00:30:51.687811Z",
          "shell.execute_reply.started": "2021-11-01T00:30:50.931438Z",
          "shell.execute_reply": "2021-11-01T00:30:51.686911Z"
        },
        "trusted": true,
        "id": "S-jq4tjdCce3"
      },
      "source": [
        "#@markdown ## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹\n",
        "#@markdown - Google Cloud Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆ\n",
        "#@markdown   - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® URL ã‚’æŒ‡å®š\n",
        "#@markdown   - ä¾‹: `gs://mybucket/path/to/dataset_dir`\n",
        "#@markdown - Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆ\n",
        "#@markdown   - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "#@markdown   - ä¾‹: `/content/drive/MyDrive/dataset`\n",
        "GCS_PATH = \"/content/drive/MyDrive/dataset\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ## å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã©ã†ã‹\n",
        "#@markdown\n",
        "#@markdown éå¸¸ã«å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç”»åƒ10ä¸‡æšä»¥ä¸Šï¼‰ã§ã¯ã€ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "#@markdown\n",
        "#@markdown ã“ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’é¸æŠã™ã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹å‡¦ç†ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚\n",
        "#\n",
        "# True ã®ã¨ãã¯ OOM å›é¿ã®ãŸã‚ã«\n",
        "# - å­¦ç¿’æ™‚ã€ã‚¨ãƒãƒƒã‚¯ã”ã¨ã® validation ã‚’çœç•¥ã™ã‚‹\n",
        "# - æ¨è«–æ™‚ã€é…ã„ãŒ OOM ã«ãªã‚‰ãªã„æ‰‹æ³•ã‚’ä½¿ã†\n",
        "HUGE_DATASET = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ## å­¦ç¿’ç”»åƒæšæ•°\n",
        "#@markdown \n",
        "#@markdown `train` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å«ã¾ã‚Œã‚‹ç”»åƒæ•°ã®åˆè¨ˆã‚’å…¥åŠ›ã—ã¾ã™ã€‚\n",
        "NUM_TRAINING_IMAGES = 792 #@param {type: \"number\"}\n",
        "#@markdown ## æ¨è«–ç”»åƒæšæ•°\n",
        "#@markdown \n",
        "#@markdown `validation` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å«ã¾ã‚Œã‚‹ç”»åƒæ•°ã®åˆè¨ˆã‚’å…¥åŠ›ã—ã¾ã™ã€‚\n",
        "NUM_VALIDATION_IMAGES = 247 #@param {type: \"number\"}\n",
        "NUM_TEST_IMAGES = NUM_VALIDATION_IMAGES\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "# TF-Hub ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹\n",
        "CORE_LAYER_PATH = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2'\n",
        "\n",
        "# ç”»åƒã‚µã‚¤ã‚º [H, W]\n",
        "IMAGE_SIZE = [512, 512]\n",
        "# ãƒªã‚µã‚¤ã‚ºæ–¹å¼ (\"RESIZE\": æ‹¡å¤§ãƒ»ç¸®å°, \"PAD\": ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°)\n",
        "RESIZE_METHOD = \"RESIZE\"\n",
        "#@markdown ## ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
        "#@markdown \n",
        "#@markdown 1ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆ1å›ã®ãƒ¢ãƒ‡ãƒ«æ›´æ–°ï¼‰ã§ä½¿ç”¨ã™ã‚‹ç”»åƒã®æ•°ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "#@markdown \n",
        "#@markdown ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©å­¦ç¿’é€Ÿåº¦ãŒå‘ä¸Šã—ã¾ã™ãŒã€å¤§ãã™ãã‚‹ã¨ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ã€‚\n",
        "#@markdown \n",
        "#@markdown ç›®å®‰ã¯ `256` (TPU)ã€`4` (GPU) ã§ã™ã€‚\n",
        "BATCH_SIZE = 4 #@param {type: \"number\"}\n",
        "# ã‚¨ãƒãƒƒã‚¯æ•°\n",
        "EPOCHS = 30\n",
        "\n",
        "# 90åº¦ãšã¤å›è»¢ã™ã‚‹æ°´å¢—ã— (bool)\n",
        "AUG_ROTATE = True\n",
        "# RandAug (bool)\n",
        "AUG_RANDAUG = False\n",
        "AUG_RANDAUG_N = 2 # ãƒ¬ã‚¤ãƒ¤æ•°\n",
        "AUG_RANDAUG_M = 5 # ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰\n",
        "# > 0.0 ãªã‚‰ã° Mixup ã‚’é©ç”¨\n",
        "AUG_MIXUP = 0.0\n",
        "# 1.2å€ / 0.8å€ã®æ‹¡å¤§ãƒ»ç¸®å° (bool)\n",
        "AUG_ZOOM = False\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown\n",
        "#@markdown ## è»¢ç§»å­¦ç¿’å…ƒãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
        "#@markdown\n",
        "#@markdown è»¢ç§»å­¦ç¿’ï¼ˆå­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚‚ã¨ã«ã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ï¼‰ã®è¨­å®šã§ã™ã€‚\n",
        "#@markdown\n",
        "#@markdown è»¢ç§»å­¦ç¿’ã—ãªã„ã¨ãã¯ `None` ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "#@markdown\n",
        "#@markdown è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ã¨ãã¯ã€è»¢ç§»å­¦ç¿’å…ƒã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "#@markdown\n",
        "#@markdown * ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®2ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚  \n",
        "#@markdown   ãƒ•ã‚¡ã‚¤ãƒ«åã®å…±é€šã™ã‚‹éƒ¨åˆ†ã‚’ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ã—ã¦æŒ‡å®šã—ã¾ã™ã€‚  \n",
        "#@markdown\n",
        "#@markdown   ä¾‹: ä¸‹è¨˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è»¢ç§»å­¦ç¿’ã™ã‚‹ã¨ã\n",
        "#@markdown      ```\n",
        "#@markdown      ckpt-30.data-00000-of-00001`\n",
        "#@markdown      ckpt-30.index`\n",
        "#@markdown      ```\n",
        "#@markdown   â†’ `\"gs://bucket/path/to/ckpt-30\"` ã®ã‚ˆã†ã«æŒ‡å®šã—ã¾ã™ã€‚\n",
        "#@markdown * Google Cloud Storage ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‚ç…§ã™ã‚‹å ´åˆ\n",
        "#@markdown   * ãƒ¢ãƒ‡ãƒ«ã®URLã‚’æŒ‡å®š\n",
        "#@markdown   * ä¾‹: `\"gs://bucket/my_training/ckpt-30\"`\n",
        "#@markdown * Google Drive ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’å‚ç…§ã™ã‚‹å ´åˆ\n",
        "#@markdown   * ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "#@markdown   * ä¾‹: `\"/content/drive/MyDrive/my_training/ckpt-30\"`\n",
        "TRANSFER_LEARNING_FROM = None #@param {type: \"raw\"}\n",
        "# head å±¤ã®ã¿å­¦ç¿’ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•° (HEAD_EPOCHS <= EPOCHS)\n",
        "HEAD_EPOCHS = 5\n",
        "\n",
        "# å­¦ç¿’ç‡ï¼ˆ1cycleï¼‰\n",
        "LR_RAMPUP_EPOCHS = 4\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_START = 0.00001\n",
        "LR_MAX_BASE = 0.00005   # å®Ÿéš›ã® Max å­¦ç¿’ç‡ã¯(ãƒãƒ¼ãƒ‰æ•°)å€ã«ãªã‚‹\n",
        "LR_MIN = 0.00001\n",
        "LR_EXP_DECAY = .8\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ## å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ\n",
        "#@markdown - Google Cloud Storage ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹å ´åˆ\n",
        "#@markdown   - Google Cloud Storage ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª URL ã‚’æŒ‡å®š\n",
        "#@markdown   - ä¾‹: `gs://mybucket/path/to/dataset_dir`\n",
        "#@markdown   - ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã‚’ TPU ã«ã‚»ãƒƒãƒˆã™ã‚‹å ´åˆã¯ã€Cloud Storage ã«ä¿å­˜ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™\n",
        "#@markdown - Google Drive ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹å ´åˆ\n",
        "#@markdown   - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "#@markdown   - ä¾‹: `/content/drive/MyDrive/model`\n",
        "LOG_DIR = \"/content/drive/MyDrive/custom_ai/model.tflite\" #@param {type: \"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-11-01T00:29:26.649202Z",
          "iopub.execute_input": "2021-11-01T00:29:26.649614Z",
          "iopub.status.idle": "2021-11-01T00:29:26.657182Z",
          "shell.execute_reply.started": "2021-11-01T00:29:26.649573Z",
          "shell.execute_reply": "2021-11-01T00:29:26.656019Z"
        },
        "trusted": true,
        "id": "L3sf5XL0Ccei"
      },
      "source": [
        "import math, re, os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics \\\n",
        "    import f1_score, precision_score, recall_score, confusion_matrix\n",
        "from functools import partial\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synset_id2label_path = os.path.join(GCS_PATH, \"synset_id2label.json\") \n",
        "\n",
        "with tf.io.gfile.GFile(synset_id2label_path, \"r\") as f:\n",
        "    synset_id2label = json.loads(f.read())\n",
        "\n",
        "class_id_sorted = sorted(synset_id2label, key=lambda k: int(k))\n",
        "CLASSES = [synset_id2label[k] for k in class_id_sorted]"
      ],
      "metadata": {
        "id": "Gy4wwhz2GefG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TFRecord ã®ã‚¯ãƒ©ã‚¹ã‚’èª­ã¿æ›¿ãˆã‚‹ã‹ã©ã†ã‹\n",
        "#REMAP_CLASSES = False\n",
        "#\n",
        "### TFRecord ã®ã‚¯ãƒ©ã‚¹èª­ã¿æ›¿ãˆç”¨è¾æ›¸\n",
        "###  - key ã« TFRecord ä½œæˆæ™‚ã®ã‚¯ãƒ©ã‚¹å\n",
        "###  - value ã«èª­ã¿æ›¿ãˆå¾Œã®ã‚¯ãƒ©ã‚¹å\n",
        "### ã‚’æ›¸ãã¨ã€TFRecord ã®ã‚¯ãƒ©ã‚¹åã‚’èª­ã¿æ›¿ãˆã¦å­¦ç¿’ã§ãã¾ã™\n",
        "#remap_dict = {\n",
        "#    \"1_fruit_azamiuma\": \"1_fruit_azamiuma\",\n",
        "#    \"1_fruit_healthy\": \"1_fruit_healthy\",\n",
        "#    \"1_fruit_otabakoga\": \"1_fruit_otabakoga\",\n",
        "#    \"1_leaf_aburamushi\": \"aburamushi\",\n",
        "#    \"1_leaf_azamiuma\": \"leaf_azamiuma\",\n",
        "#    \"1_leaf_hamoguribae\": \"leaf_hamoguribae\",\n",
        "#    \"1_leaf_hasumonyoto\": \"leaf_hasumonyoto\",\n",
        "#    \"1_leaf_healthy\": \"leaf_healthy\",\n",
        "#    \"1_leaf_konajirami\": \"konajirami\",\n",
        "#    \"1_leaf_tomatosabidani\": \"1_leaf_tomatosabidani\",\n",
        "#}\n",
        "#\n",
        "### èª­ã¿æ›¿ãˆç”¨ã®ãƒªã‚¹ãƒˆã‚’å®šç¾©\n",
        "### Remaps labels in TFRecord to the labels given.\n",
        "### Note that labels start from 1, not 0.\n",
        "### e.g.) read_tfrecord(..., relabel=[1,1,2])\n",
        "###   -> The model interprets labels 1 and 2 from TFRecord as label 1\n",
        "###                           label 3 from TFRecord as label 2\n",
        "#if REMAP_CLASSES:\n",
        "#    relabel_list = []\n",
        "#    new_id2label = list(sorted(set(remap_dict.values())))\n",
        "#\n",
        "#    for k in sorted(remap_dict.keys()):\n",
        "#        v = remap_dict[k]\n",
        "#        new_idx = new_id2label.index(v) + 1\n",
        "#        print(f'Old class \"{k}\" is mapped to \"{v}\" ({new_idx})')\n",
        "#        relabel_list.append(new_idx)\n",
        "#\n",
        "#    ## CLASSES ã‚’å„æ‰€ã§ä½¿ã£ã¦ã„ã‚‹ã€‚å†å®šç¾©ã™ã‚‹\n",
        "#    CLASSES = new_id2label\n",
        "#else:\n",
        "#    print(\"Remapping will not be applied.\")\n",
        "relabel_list = None"
      ],
      "metadata": {
        "id": "bVn4JpjU-cCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## è¨ˆç®—ãƒãƒ¼ãƒ‰ï¼ˆTPU/GPU/CPUï¼‰ã®åˆ¤åˆ¥\n",
        "try: # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError: # detect GPUs\n",
        "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "    #raise Exception(\"I find your lack of TPUs disappointing.\")\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "## å…¥åŠ›å€¤ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "assert HEAD_EPOCHS <= EPOCHS, f'Hey, training the head until epoch {HEAD_EPOCHS}, '\\\n",
        "    f'then all layers until epoch {EPOCHS}, makes no sense.'\n",
        "allowed_resize_methods = (\"RESIZE\", \"PAD\")\n",
        "assert RESIZE_METHOD in allowed_resize_methods, \\\n",
        "    f\"Invalid RESIZE_METHOD: {RESIZE_METHOD}. Choose from {allowed_resize_methods}.\"\n",
        "\n",
        "training_dirpath = os.path.join(GCS_PATH, \"train-*\")\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(training_dirpath)\n",
        "validation_dirpath = os.path.join(GCS_PATH, \"validation-*\")\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(validation_dirpath)\n",
        "TEST_FILENAMES = VALIDATION_FILENAMES\n",
        "\n",
        "def lrfn(epoch):\n",
        "    LR_MAX = LR_MAX_BASE * strategy.num_replicas_in_sync\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "    \n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "y = [lrfn(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "id": "Kln1fac1-S6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNmSkwnZCce6"
      },
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76mp1DIU4FYO"
      },
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
        "## Data augmentation\n",
        "def random_flip(image):\n",
        "    '''ç”»åƒã‚’æ°´å¹³ãƒ»å‚ç›´åè»¢ã—ã¦è¿”ã—ã¾ã™\n",
        "    '''\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_rot90(image):\n",
        "    '''Randomly rotates the image by (n / 2) * pi radian. (n=0,1,2,3)\n",
        "    ç”»åƒã‚’90åº¦/180åº¦/270åº¦ã ã‘å›è»¢ã—ã¦è¿”ã—ã¾ã™\n",
        "    '''\n",
        "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
        "    image = tf.cond(k >= 1,\n",
        "                    true_fn=lambda: tf.image.rot90(image, k=k),\n",
        "                    false_fn=lambda: image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
        "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
        "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
        "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
        "\n",
        "\n",
        "def mix_up(ds_one, ds_two, alpha=0.2):\n",
        "    # Unpack two datasets\n",
        "    images_one, labels_one = ds_one\n",
        "    images_two, labels_two = ds_two\n",
        "    batch_size = tf.shape(images_one)[0]\n",
        "\n",
        "    # Sample lambda and reshape it to do the mixup\n",
        "    l = sample_beta_distribution(batch_size, alpha, alpha)\n",
        "    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n",
        "    y_l = tf.reshape(l, (batch_size, 1))\n",
        "\n",
        "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "    # (one from each dataset) into one image/label\n",
        "    images = images_one * x_l + images_two * (1 - x_l)\n",
        "    labels = labels_one * y_l + labels_two * (1 - y_l)\n",
        "    return (images, labels)\n",
        "\n",
        "\n",
        "def randaug(image, num_layers=2, magnitude=15):\n",
        "    '''RandAugment ã‚’é©ç”¨ã—ã¾ã™\n",
        "    (æœ¬å®¶ EffNet-V2 ã‹ã‚‰æµç”¨ã—ãŸ TensorFlow ç´”æ­£ã®å®Ÿè£…)\n",
        "    Args:\n",
        "        image: `tf.Tensor`, å€¤åŸŸ [0,1]\n",
        "        num_layers: `int`, ãƒ¬ã‚¤ãƒ¤æ•°\n",
        "        magnitude: `int`, ç”»åƒåŠ¹æœã®å¼·åº¦\n",
        "    Returns:\n",
        "        `tf.Tensor` å½¢å¼ã®ç”»åƒ, å€¤åŸŸ [0,1]\n",
        "    '''\n",
        "    print(\"Applying RandAugment.\")\n",
        "    image *= 255\n",
        "    input_image_type = image.dtype\n",
        "    image = tf.clip_by_value(image, 0.0, 255.0)\n",
        "    image = tf.cast(image, dtype=tf.uint8)  # float ã§ã¯???\n",
        "    image = autoaugment.distort_image(\n",
        "        image, aug_name='randaug', ra_num_layers=num_layers, \n",
        "        ra_magnitude=magnitude)\n",
        "    image = tf.cast(image, dtype=input_image_type)\n",
        "    image /= 255\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def zoom(image):\n",
        "    \"\"\"Zooms the image by factor of 1.2.\"\"\"\n",
        "    shape = tf.shape(image)\n",
        "    ## Zoom by (about) 1.2x\n",
        "    image = tf.image.central_crop(image, 0.8)\n",
        "    ## Then crop\n",
        "    image = tf.image.resize(image, shape[:2])\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def mooz(image):\n",
        "    \"\"\"Moozes the image by factor of 0.8.\"\"\"\n",
        "    shape = tf.shape(image)\n",
        "    s0 = tf.cast(shape[0], tf.float32)\n",
        "    s1 = tf.cast(shape[1], tf.float32)\n",
        "    ## Increases the image size by 1.2x with pad\n",
        "    image = tf.image.pad_to_bounding_box(\n",
        "        image,\n",
        "        offset_height=tf.cast(s0*0.1, tf.int32),\n",
        "        offset_width=tf.cast(s1*0.1, tf.int32),\n",
        "        target_height=tf.cast(s0*1.2, tf.int32),\n",
        "        target_width=tf.cast(s1*1.2, tf.int32))\n",
        "    ## Then resizes to the original shape\n",
        "    image = tf.image.resize(image, shape[:2])\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_zoom_mooz(image):\n",
        "    '''ç”»åƒã‚’1/3ã®ç¢ºç‡ã§æ‹¡å¤§åˆ‡ã‚ŠæŠœãã€ç¸®å°ã—ã¦ã€ã¾ãŸã¯ãã®ã¾ã¾è¿”ã—ã¾ã™\n",
        "    æ‹¡å¤§ãƒ»ç¸®å°ã®ä¸­å¿ƒç‚¹ã¯ã€ç”»åƒã®ä¸­å¿ƒã§ã™\n",
        "    Args:\n",
        "        image: `tf.Tensor`\n",
        "    Returns:\n",
        "        `tf.Tensor` å½¢å¼ã®ç”»åƒã€å¹…ã¨é«˜ã•ã¯ image ã¨åŒã˜\n",
        "    '''\n",
        "    k = tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32)\n",
        "    image = tf.cond(k == 1,\n",
        "                    true_fn=lambda: zoom(image),\n",
        "                    false_fn=lambda: image)\n",
        "    image = tf.cond(k == 2,\n",
        "                    true_fn=lambda: mooz(image),\n",
        "                    false_fn=lambda: image)\n",
        "\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2021-11-01T00:31:12.854328Z",
          "iopub.execute_input": "2021-11-01T00:31:12.854603Z",
          "iopub.status.idle": "2021-11-01T00:31:12.87609Z",
          "shell.execute_reply.started": "2021-11-01T00:31:12.854576Z",
          "shell.execute_reply": "2021-11-01T00:31:12.875259Z"
        },
        "trusted": true,
        "id": "o7J18GdwCce7"
      },
      "source": [
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "\n",
        "    ## RESIZE_METHOD ã«å¿œã˜ã¦ã€ã‚µã‚¤ã‚ºåˆã‚ã›ã®æ–¹æ³•ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°/ãƒªã‚µã‚¤ã‚ºï¼‰ã‚’åˆ‡ã‚Šæ›¿ãˆ\n",
        "    if RESIZE_METHOD == \"PAD\":\n",
        "        image = tf.image.resize_with_pad(\n",
        "            image, IMAGE_SIZE[0], IMAGE_SIZE[1], \n",
        "            method=tf.image.ResizeMethod.BICUBIC)\n",
        "    else:\n",
        "        image = tf.image.resize(\n",
        "            image, IMAGE_SIZE, method=tf.image.ResizeMethod.BICUBIC)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def read_tfrecord(example, labeled, one_hot=False, relabel=None):\n",
        "    '''Parses Google AutoML-style TFRecord dataset.\n",
        "    Args:\n",
        "        example\n",
        "        labeled\n",
        "        one_hot\n",
        "        relabel: `list`. Remaps labels in TFRecord to the labels given.\n",
        "            Note that labels start from 1, not 0.\n",
        "            e.g.) read_tfrecord(..., relabel=[1,1,2])\n",
        "              -> The model interprets labels 1 and 2 from TFRecord as label 1\n",
        "                                      label 3 from TFRecord as label 2\n",
        "    '''\n",
        "    tfrecord_format = (\n",
        "        {\n",
        "            \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
        "            \"image/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "        if labeled\n",
        "        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n",
        "    )\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example[\"image/encoded\"])\n",
        "    image /= 255\n",
        "    if labeled:\n",
        "        label = tf.cast(example[\"image/class/label\"], tf.int64)\n",
        "        if relabel is not None:\n",
        "            label -= 1  # Since (image/class/label == 1) maps to relabel[0] \n",
        "            relabel_t = tf.constant(relabel, tf.float32)\n",
        "            label = tf.gather(relabel_t, label)\n",
        "        label -= 1\n",
        "        if one_hot:\n",
        "            print(\"One hot is active!\")\n",
        "            label = tf.cast(label, tf.uint8)\n",
        "            label = tf.one_hot(label, len(CLASSES))\n",
        "            label = tf.cast(label, tf.float32)\n",
        "        return image, label\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_dataset(\n",
        "        filenames, labeled=True, ordered=False, one_hot=False, relabel=None):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False  \n",
        "            # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames)  \n",
        "        # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "        # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(\n",
        "        partial(\n",
        "            read_tfrecord, labeled=labeled, one_hot=one_hot, relabel=relabel),\n",
        "        num_parallel_calls=AUTO)\n",
        "        # returns a dataset of (image, label) pairs if labeled=True \n",
        "        # or just images if labeled=False\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def _get_training_dataset(\n",
        "    aug_rotate=False, one_hot=False, aug_randaug=False, aug_zoom=False,\n",
        "    randaug_num_layers=2, randaug_magnitude=15, relabel=None):\n",
        "    '''Obtain the training datset.\n",
        "    Args:\n",
        "      aug_rotate: `bool`. If true, performs random rotation and flip.\n",
        "      one_hot: `bool`, True ãªã‚‰ã°ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆç¬¦å·åŒ–ã™ã‚‹ï¼ˆMixupç”¨ï¼‰\n",
        "      aug_randaug: `bool`. True ãªã‚‰ã°ã€RandAugment ã‚’é©ç”¨ã™ã‚‹\n",
        "      aug_zoom: `bool`. True ãªã‚‰ã°ã€æ‹¡å¤§ãƒ»ç¸®å°æ°´å¢—ã—ã‚’é©ç”¨ã™ã‚‹\n",
        "      randaug_num_layers: `int`, RandAugment ã®ãƒ¬ã‚¤ãƒ¤æ•°\n",
        "      randaug_magnitude: `int`, RandAugment ã®ç”»åƒåŠ¹æœã®å¼·åº¦\n",
        "      relabel: `dict` or None, `dict` ãªã‚‰ã° TFRecord ã®ãƒ©ãƒ™ãƒ«ã‚’èª­ã¿æ›¿ãˆã‚‹\n",
        "    '''\n",
        "    dataset = load_dataset(\n",
        "        TRAINING_FILENAMES, labeled=True, one_hot=one_hot, relabel=relabel)\n",
        "\n",
        "    if aug_rotate:\n",
        "        dataset = dataset.map(\n",
        "            lambda x, y: (random_flip(x), y),\n",
        "            num_parallel_calls=AUTO)\n",
        "        dataset = dataset.map(\n",
        "            lambda x, y: (random_rot90(x), y), \n",
        "            num_parallel_calls=AUTO)\n",
        "\n",
        "    if aug_randaug:\n",
        "        dataset = dataset.map(\n",
        "            lambda x, y: (\n",
        "                randaug(\n",
        "                    x, num_layers=randaug_num_layers, \n",
        "                    magnitude=randaug_magnitude),\n",
        "                y), \n",
        "            num_parallel_calls=AUTO)\n",
        "\n",
        "    if aug_zoom:\n",
        "        dataset = dataset.map(\n",
        "            lambda x, y: (random_zoom_mooz(x), y),\n",
        "            num_parallel_calls=AUTO)\n",
        "\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_training_dataset(aug_mixup=0.0, **kwargs):\n",
        "    '''Wraps _get_training_dataset to add mixup functionality.\n",
        "    Args:\n",
        "      aug_mixup  `float`. If > 0.0, performs mixup augmentation.\n",
        "      **kwargs   See the definition of _get_training_dataset().'''\n",
        "    if aug_mixup == 0.0:\n",
        "        print('Mixup is disabled.')\n",
        "        return _get_training_dataset(**kwargs)\n",
        "    else:\n",
        "        print('Mixup is enabled.')\n",
        "        dataset_1 = _get_training_dataset(one_hot=True, **kwargs)\n",
        "        dataset_2 = _get_training_dataset(one_hot=True, **kwargs)\n",
        "        train_ds = tf.data.Dataset.zip((dataset_1, dataset_2))\n",
        "        train_ds = train_ds.map(\n",
        "            lambda ds1, ds2: mix_up(ds1, ds2, alpha=aug_mixup),\n",
        "            num_parallel_calls=AUTO)\n",
        "        return train_ds\n",
        "\n",
        "    \n",
        "def get_validation_dataset(ordered=False, one_hot=False, relabel=None):\n",
        "    dataset = load_dataset(\n",
        "        VALIDATION_FILENAMES, labeled=True, ordered=ordered, one_hot=one_hot,\n",
        "        relabel=relabel)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_test_dataset(ordered=False, relabel=None):\n",
        "    dataset = load_dataset(\n",
        "        TEST_FILENAMES, labeled=False, ordered=ordered, relabel=relabel)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "NUM_TEST_IMAGES = NUM_VALIDATION_IMAGES\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "VALIDATION_STEPS = -(-NUM_VALIDATION_IMAGES // BATCH_SIZE) # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "TEST_STEPS = -(-NUM_TEST_IMAGES // BATCH_SIZE)             # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeZmzk7XCcfA"
      },
      "source": [
        "# ãƒ¢ãƒ‡ãƒ«å®šç¾©"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hToqYke6eil"
      },
      "source": [
        "## Custom callbacks, from the original EffNet-V2\n",
        "## \n",
        "class ReusableBackupAndRestore(tf.keras.callbacks.BackupAndRestore):\n",
        "  \"\"\"A BackupAndRestore callback that can be used across multiple model.fit()s.\"\"\"\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    # don't delete the backup, so it can be used for future model.fit()s\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-01T00:32:04.957262Z",
          "iopub.execute_input": "2021-11-01T00:32:04.958165Z",
          "iopub.status.idle": "2021-11-01T00:32:40.403626Z",
          "shell.execute_reply.started": "2021-11-01T00:32:04.958108Z",
          "shell.execute_reply": "2021-11-01T00:32:40.402712Z"
        },
        "trusted": true,
        "id": "ybid_m_7CcfA"
      },
      "source": [
        "with strategy.scope():\n",
        "    # TF>=2.4: load models from TF Hub directly to the TPU\n",
        "    load_locally = tf.saved_model.LoadOptions(\n",
        "        experimental_io_device='/job:localhost')\n",
        "    pretrained_model = hub.KerasLayer(\n",
        "        CORE_LAYER_PATH, trainable=True, input_shape=[*IMAGE_SIZE, 3], \n",
        "        load_options=load_locally)\n",
        "    model = tf.keras.Sequential([\n",
        "        # the expected image format for all TFHub image models is float32 in\n",
        "        # [0,1) range\n",
        "        tf.keras.layers.Lambda(\n",
        "            lambda data: tf.image.convert_image_dtype(data, tf.float32), \n",
        "            input_shape=[*IMAGE_SIZE, 3]),\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Optionally make the core layer untrainable (train only the head).\n",
        "    if HEAD_EPOCHS >= 1:\n",
        "        model.layers[1].trainable = False\n",
        "\n",
        "    ## Optionally initialize the model with pretrained data.\n",
        "    if TRANSFER_LEARNING_FROM is not None:\n",
        "        ## Remove the last layer, load weights, then attach a fresh head.\n",
        "        model.pop()\n",
        "        model.load_weights(TRANSFER_LEARNING_FROM)\n",
        "        model.add(tf.keras.layers.Dense(len(CLASSES), activation='softmax'))\n",
        "\n",
        "\n",
        "## æå¤±é–¢æ•°: Mixupã‚ã‚Šï¼ˆOne-hotï¼‰ã®å ´åˆã¯ categorical_crossentropy\n",
        "##          Mixupãªã—ã®å ´åˆã¯ sparse_categorical_crossentropy\n",
        "loss_fn = 'categorical_crossentropy' if AUG_MIXUP > 0 \\\n",
        "          else 'sparse_categorical_crossentropy'\n",
        "print(f\"Loss function: {loss_fn}\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy'],\n",
        "    steps_per_execution=16,\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtbYWhj3CcfA"
      },
      "source": [
        "# å­¦ç¿’"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = get_training_dataset(\n",
        "    aug_rotate=AUG_ROTATE, aug_mixup=AUG_MIXUP, aug_randaug=AUG_RANDAUG, \n",
        "    aug_zoom=AUG_ZOOM, randaug_num_layers=AUG_RANDAUG_N, \n",
        "    randaug_magnitude=AUG_RANDAUG_M, relabel=relabel_list)\n",
        "\n",
        "callbacks = [\n",
        "    lr_callback,\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        os.path.join(LOG_DIR, 'ckpt-{epoch:d}'), verbose=1,\n",
        "        save_weights_only=True),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, update_freq=100),\n",
        "    ReusableBackupAndRestore(backup_dir=LOG_DIR),\n",
        "]\n",
        "\n",
        "## å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã¨ãã¯ã€å­¦ç¿’æ™‚ã® validation ã‚’çœç•¥ã—ã¦ OOM å›é¿\n",
        "if HUGE_DATASET:\n",
        "    args_validation = {}\n",
        "else:\n",
        "    args_validation = {\n",
        "        \"validation_data\": get_validation_dataset(one_hot=(AUG_MIXUP>0.0)),\n",
        "        \"validation_steps\": VALIDATION_STEPS,\n",
        "    }\n",
        "\n",
        "## HEAD_EPOCHS ãŒ 1 ä»¥ä¸Šã®ã¨ãã¯\n",
        "##  - å…ˆã« head å±¤ã‚’ HEAD_EPOCHS ã¾ã§å­¦ç¿’ã™ã‚‹\n",
        "##  - å…¨ãƒ¬ã‚¤ãƒ¤ã‚’å­¦ç¿’å¯èƒ½ã«ã—ã¦ã€å†åº¦å­¦ç¿’ã™ã‚‹\n",
        "if HEAD_EPOCHS >= 1:\n",
        "    history = model.fit(\n",
        "        train_ds, steps_per_epoch=STEPS_PER_EPOCH, epochs=HEAD_EPOCHS, \n",
        "        callbacks=callbacks, verbose=2, **args_validation)\n",
        "    model.layers[1].trainable = True\n",
        "    model.summary()\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=loss_fn,\n",
        "        metrics=['accuracy'],\n",
        "        steps_per_execution=16,\n",
        "        )\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, \n",
        "    callbacks=callbacks, verbose=2, **args_validation)"
      ],
      "metadata": {
        "id": "5voVx17o1hhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PwktbhnCcfC"
      },
      "source": [
        "# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCbDf37uDCv5"
      },
      "source": [
        "final_ckpt_path = os.path.join(LOG_DIR, f'ckpt-{EPOCHS}')\n",
        "model.load_weights(final_ckpt_path)\n",
        "\n",
        "if not HUGE_DATASET:\n",
        "    cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "    images_ds = cmdataset.map(lambda image, label: image)\n",
        "    labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "    cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch\n",
        "    cm_probabilities = model.predict(images_ds, steps=VALIDATION_STEPS)\n",
        "    cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "    cm_predictions = cm_predictions[:NUM_VALIDATION_IMAGES] \n",
        "        # Lest some validation data are counted twice\n",
        "    #print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
        "    #print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)\n",
        "\n",
        "if HUGE_DATASET:\n",
        "    import keras.backend as K\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    ## å·¨å¤§ï¼ˆç”»åƒæ•°ä¸‡æšã€ç”»åƒã‚µã‚¤ã‚º1408ï¼‰ãª tf.Dataset ã§æ¨è«–ã™ã‚‹ã¨ OOM ã«ãªã‚‹\n",
        "    ## - GPU ã§ã¯ãƒ›ã‚¹ãƒˆã®RAMã‚’ä½¿ã„æœãŸã—ã¦ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹\n",
        "    ## - TPU ã§ã¯ `Socket closed` ã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã‚‹\n",
        "    ## é–¢é€£ï¼Ÿ: https://github.com/keras-team/keras/issues/13118\n",
        "    ##\n",
        "    ## å¯¾ç­–ã¨ã—ã¦ã€tf.Dataset ã‚’ model ã«æ¸¡ã•ãšã€\n",
        "    ## ãƒ›ã‚¹ãƒˆVMå´ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°‘ã—ãšã¤èª­ã¿ã ã—ã¦ (`model(x)`)ã€TPU ã«æ¨è«–ã•ã›ã‚‹\n",
        "    ## å‹•ä½œé€Ÿåº¦ãŒé…ããªã‚‹ãŒã€æ¨è«–ã¯ã§ãã‚‹\n",
        "    ## æ³¨æ„: GPU ã§ã¯ OOM ã«ãªã‚‹\n",
        "    BS = 64\n",
        "    TAKE = int((NUM_VALIDATION_IMAGES // BS) * 1)\n",
        "    data_len = BS * TAKE\n",
        "\n",
        "    cm_correct_labels = np.empty((data_len), dtype=int)    # Stores GTs\n",
        "    cm_predictions = np.empty((data_len), dtype=int)       # Stores preds\n",
        "\n",
        "    cmdataset = tf.data.TFRecordDataset(VALIDATION_FILENAMES)\n",
        "    dataset = cmdataset.map(\n",
        "        partial(\n",
        "            read_tfrecord, labeled=True, one_hot=False, relabel=relabel_list),\n",
        "        num_parallel_calls=AUTO)\n",
        "    \n",
        "    for i, batch in tqdm(\n",
        "            enumerate(dataset.shuffle(100).batch(BS).take(TAKE)), total=TAKE):\n",
        "        images_batch, labels_batch = batch\n",
        "        images_batch = tf.squeeze(images_batch)\n",
        "            # (bs, 1, h, w, c) -> (bs, h, w, c)\n",
        "        prob_y = model(images_batch, training=False) \n",
        "            # since model.predict() causes OOM\n",
        "        pred_y = tf.math.argmax(prob_y, axis=-1)\n",
        "        labels_batch = tf.cast(labels_batch, tf.int8)\n",
        "        labels_batch = tf.squeeze(labels_batch)\n",
        "\n",
        "        # çµæœã‚’ä¿å­˜\n",
        "        idx_from = i * BS\n",
        "        idx_to = idx_from + BS\n",
        "        cm_correct_labels[idx_from:idx_to] = labels_batch\n",
        "        cm_predictions[idx_from:idx_to] = pred_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "daKfKXe4CcfC"
      },
      "source": [
        "## Få€¤ãªã©ã®ç®—å‡º\n",
        "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n",
        "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
        "#display_confusion_matrix(cmat, score, precision, recall)\n",
        "print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR4dSE1jWFc0"
      },
      "source": [
        "## æ··åŒè¡Œåˆ—ã‚’CSVå½¢å¼ã§å‡ºåŠ›\n",
        "import pandas as pd\n",
        "cmat = confusion_matrix(\n",
        "    cm_correct_labels, cm_predictions, \n",
        "    labels=range(len(np.unique(cm_correct_labels))))\n",
        "df = pd.DataFrame(cmat, index=CLASSES, columns=CLASSES)\n",
        "print(df.to_csv())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Top-1ç²¾åº¦ã®ç®—å‡º\n",
        "top_1_acc = (cm_correct_labels == cm_predictions).sum() / len(cm_correct_labels)\n",
        "print(f'top_1_accuracy: {top_1_acc * 100:.1f}%')"
      ],
      "metadata": {
        "id": "qGv-meaOryRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›\n",
        "\n",
        "å­¦ç¿’æ¸ˆã¿ã®ç”»åƒè­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’ã€ã‚¨ãƒƒã‚¸ç«¯æœ«ã§å‹•ä½œå¯èƒ½ãªå½¢å¼ï¼ˆTFLiteï¼‰ã«å¤‰æ›ã—ã¾ã™ã€‚\n",
        "\n",
        "å¤‰æ›ã«ã‚ˆã‚Šã€è­˜åˆ¥æ€§èƒ½ã¯ã‚„ã‚„ä½ä¸‹ã—ã¾ã™ã€‚\n",
        "\n",
        "> âš ï¸æ³¨æ„âš ï¸\n",
        "> \n",
        "> ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã®è¨­å®šãŒ TPU ã®ã¨ãã«å¤‰æ›ã‚’è©¦ã¿ã‚‹ã¨ã€`converter.convert()` ã®éƒ¨åˆ†ã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ï¼š\n",
        ">\n",
        "> ```\n",
        "> ValueError: Device /job:worker/replica:0/task:0/device:CPU:0 is not found\n",
        "> ```\n",
        ">\n",
        "> ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã®è¨­å®šãŒ TPU ã«ãªã£ã¦ã„ã‚‹å ´åˆã¯ã€**ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã‚’TPUä»¥å¤–ã«è¨­å®šã—ã¦VMã‚’å†èµ·å‹•ã—ã€å­¦ç¿’ãƒ»è©•ä¾¡ä»¥å¤–ã®å„ã‚»ãƒ«ã‚’å†å®Ÿè¡Œã—ã¦ã‹ã‚‰**ä¸‹è¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n"
      ],
      "metadata": {
        "id": "NQq4_rBQlh0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## TFLite ãƒ¢ãƒ‡ãƒ«ã®æ›¸ãå‡ºã—å…ˆ\n",
        "#@markdown\n",
        "#@markdown æ›¸ãå‡ºã™ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "#@markdown\n",
        "#@markdown Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ã„ã‚‹å ´åˆã¯ã€`/content/drive/MyDrive/` ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€Google Drive ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã§ãã¾ã™ã€‚\n",
        "#@markdown\n",
        "#@markdown ä¾‹: `/content/drive/MyDrive/model.tflite` (Google Drive ã«æ›¸ãå‡ºã™å ´åˆ)\n",
        "EXPORT_TFLITE_TO = \"/content/drive/MyDrive/model.tflite\" #@param {type: \"string\"}"
      ],
      "metadata": {
        "id": "DX13CN2gW2vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_ckpt_path = os.path.join(LOG_DIR, f'ckpt-{EPOCHS}')\n",
        "print(f\"Loading {final_ckpt_path}\")\n",
        "model.load_weights(final_ckpt_path)"
      ],
      "metadata": {
        "id": "XcvwqNCHCllc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from pathlib import Path\n",
        "\n",
        "## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š\n",
        "optimize_lite_model = True\n",
        "quantize_lite_model = True\n",
        "num_calibration_examples = 100\n",
        "tflite_export_path = Path(EXPORT_TFLITE_TO)\n",
        "\n",
        "representative_dataset = None\n",
        "\n",
        "## validation ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€è»½é‡åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹\n",
        "if optimize_lite_model and num_calibration_examples:\n",
        "  # Use a bounded number of training examples without labels for calibration.\n",
        "  # TFLiteConverter expects a list of input tensors, each with batch size 1.\n",
        "  representative_dataset = lambda: itertools.islice(\n",
        "      ([image[None, ...]] for batch, _ in get_validation_dataset() for image in batch),\n",
        "      num_calibration_examples)\n",
        "\n",
        "## TFLite ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›\n",
        "#converter = tf.lite.TFLiteConverter.from_saved_model(LOG_DIR)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "if optimize_lite_model:\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "if quantize_lite_model:\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "if representative_dataset:  # This is optional, see above.\n",
        "    converter.representative_dataset = representative_dataset\n",
        "lite_model_content = converter.convert() # 3ï½4åˆ†ã‹ã‹ã‚‹\n",
        "\n",
        "## ä½œæˆã—ãŸ TFLite ãƒ¢ãƒ‡ãƒ«ã®æ›¸ãå‡ºã—\n",
        "tflite_export_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(tflite_export_path, \"wb\") as f:\n",
        "    f.write(lite_model_content)\n",
        "    print(\"Wrote %sTFLite model of %d bytes.\" %\n",
        "        (\"optimized \" if optimize_lite_model else \"\", len(lite_model_content)))"
      ],
      "metadata": {
        "id": "ublUnrdEk9RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TFLite ãƒ¢ãƒ‡ãƒ«ã®ã‚·ã‚°ãƒãƒãƒ£ï¼ˆå…¥å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
        "#interpreter = tf.lite.Interpreter(model_content=lite_model_content)\n",
        "## This little helper wraps the TF Lite interpreter as a numpy-to-numpy function.\n",
        "#\n",
        "#input_details = interpreter.get_input_details()\n",
        "#output_details = interpreter.get_output_details()\n",
        "#\n",
        "#print(input_details)\n",
        "#print(output_details)\n",
        "#\n",
        "#def lite_model(images):\n",
        "#  interpreter.allocate_tensors()\n",
        "#  interpreter.set_tensor(interpreter.get_input_details()[0]['index'], images)\n",
        "#  interpreter.invoke()\n",
        "#  return interpreter.get_tensor(interpreter.get_output_details()[0]['index'])"
      ],
      "metadata": {
        "id": "1cF9UGlLlFDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LICENSE\n",
        "\n",
        "Copyright 2021 MARTIN GÃ–RNER\n",
        "\n",
        "Copyright 2022 Sailaja Raja and Ronil Modi\n",
        "\n",
        "Copyright 2021 Google Inc. All rights reserved.\n",
        "\n",
        "Copyright 2021 The TensorFlow Hub Authors. All rights reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "\n",
        "Original files:\n",
        "\n",
        "* https://www.kaggle.com/code/rajasailaja/test-tpu\n",
        "* https://www.kaggle.com/code/mgornergoogle/efficientnetb7-on-100-flowers\n",
        "* https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/d617988b1cc7de73ec11a6015fd1983a6925af5e/03_image_models/03b_finetune_experiment_lr_decay_xception_flowers104.ipynb\n",
        "* https://github.com/tensorflow/hub/blob/12b09be736893efd11a0a54d85e0e01516f44442/examples/colab/tf2_image_retraining.ipynb\n",
        "* https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\n",
        "\n",
        "Major changes from the original:\n",
        "\n",
        "* Combined the above files to create a train-evaluation-quantization pipleline of EfficientV2 models"
      ],
      "metadata": {
        "id": "PTdEtsTYlgJB"
      }
    }
  ]
}